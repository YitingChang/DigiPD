{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Select a subset of input features from the dataset.\n",
    "# Unsupervised: Do not use the target variable (e.g. remove redundant variables).\n",
    "# Correlation\n",
    "# Supervised: Use the target variable (e.g. remove irrelevant variables).\n",
    "# Wrapper: Search for well-performing subsets of features.\n",
    "# RFE\n",
    "# Filter: Select subsets of features based on their relationship with the target.\n",
    "# Statistical Methods\n",
    "# Feature Importance Methods\n",
    "# Intrinsic: Algorithms that perform automatic feature selection during training.\n",
    "# Decision Trees\n",
    "# Dimensionality Reduction: Project input data into a lower-dimensional feature space.\n",
    "\n",
    "# https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79aea53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import set_printoptions, sqrt, argmax, arange\n",
    "from numpy.random import permutation\n",
    "import scipy.stats as stats\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#tsfresh\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction import extract_features, MinimalFCParameters, EfficientFCParameters\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, chi2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Self-defined functions\n",
    "from Utilities import pdVarianceThreshold, pdSelectKBest, train_val_test_split, upsampling, SelectBestClf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33048e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"E:\\\\WS4PD_data\"\n",
    "os.chdir(direc)\n",
    "save_path = os.path.join(direc, \"Model_validation\", \"GENEActiv_tremor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b69996",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5a63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_score:\n",
      "(6909, 11)\n",
      "df_sensor_feature:\n",
      "(6909, 2247)\n",
      "df_clinical_feature:\n",
      "(6909, 69)\n"
     ]
    }
   ],
   "source": [
    "## Load scores\n",
    "score_file_path = os.path.join(direc, 'Feature_extraction','score_by_device.pkl')\n",
    "df_score = pd.read_pickle(score_file_path)\n",
    "\n",
    "# Tremor: merge score 3 and 4\n",
    "df_score['tremor_GENEActivHand'].loc[df_score['tremor_GENEActivHand']==4]=3\n",
    "print('df_score:')\n",
    "print(df_score.shape)\n",
    "\n",
    "## load sensor features\n",
    "subject_ids = df_score.subject_id.unique()\n",
    "df_sensor_feature = pd.DataFrame()\n",
    "device = 'GENEActiv'\n",
    "for sb in subject_ids:\n",
    "    feature_file_path = os.path.join(direc,'Feature_extraction',device,sb + '_features.pkl')\n",
    "    df_sensor_feature_sb = pd.read_pickle(feature_file_path)\n",
    "    df_sensor_feature = pd.concat([df_sensor_feature,df_sensor_feature_sb])\n",
    "df_sensor_feature = df_sensor_feature.reset_index(drop=True)\n",
    "df_sensor_feature = df_sensor_feature.dropna(axis=1)\n",
    "print('df_sensor_feature:')\n",
    "print(df_sensor_feature.shape)\n",
    "\n",
    "## load clinical features\n",
    "meta_file_path = os.path.join(direc, 'Feature_extraction','metadata_features.pkl')\n",
    "df_clinical_feature = pd.read_pickle(meta_file_path)\n",
    "\n",
    "# drop subject_id and task_code \n",
    "# df_clinical_feature.drop(columns = ['subject_id', 'task_code'])\n",
    "df_clinical_feature = df_clinical_feature.drop(columns = 'subject_id')\n",
    "\n",
    "# One-hot encoding clinical/ categorical features\n",
    "categorical_columns = df_clinical_feature.columns\n",
    "for column in categorical_columns:\n",
    "    tempdf = pd.get_dummies(df_clinical_feature[column], prefix=column)\n",
    "    df_clinical_feature = pd.merge(\n",
    "        left=df_clinical_feature,\n",
    "        right=tempdf,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    df_clinical_feature = df_clinical_feature.drop(columns=column)\n",
    "df_clinical_feature = df_clinical_feature.dropna(axis=1)\n",
    "print('df_clinical_feature:')\n",
    "print(df_clinical_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7b4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new label for each question\n",
    "\n",
    "# Tremor\n",
    "# 1. Can wearable sensor data predict tremor score? \n",
    "# df_score['newTremorLabel_GENEActivHand'] = df_score['tremor_GENEActivHand']\n",
    "# title_name = 'Tremor score'\n",
    "# save_name = 'tremor_score'\n",
    "# xtick_name = [0,1,2,3,4]\n",
    "# bin_range = range(5)\n",
    "\n",
    "# 2. Can wearable sensor data predict whether tremor is present?\n",
    "is_tremor = df_score['tremor_GENEActivHand'].astype(int)>0\n",
    "df_score['newTremorLabel_GENEActivHand'] = np.nan\n",
    "df_score['newTremorLabel_GENEActivHand'].loc[is_tremor] = 1\n",
    "df_score['newTremorLabel_GENEActivHand'].loc[~is_tremor] = 0\n",
    "\n",
    "title_name = 'is tremor'\n",
    "save_name = 'is_tremor'\n",
    "xtick_name = [0,1]\n",
    "bin_range = range(3)\n",
    "recall_1_threshold = 0.8\n",
    "\n",
    "# 3. Can wearable sensor data predict whether tremor symptom is sever (score>2)? \n",
    "# is_sever_tremor = df_score['tremor_GENEActivHand'].astype(int)>2\n",
    "# df_score['newTremorLabel_GENEActivHand'] = np.nan\n",
    "# df_score['newTremorLabel_GENEActivHand'].loc[is_sever_tremor] = 1\n",
    "# df_score['newTremorLabel_GENEActivHand'].loc[~is_sever_tremor] = 0\n",
    "\n",
    "# title_name = 'is sever tremor (tremor score>2)'\n",
    "# save_name = 'is_sever_tremor'\n",
    "# xtick_name = [0,1]\n",
    "# bin_range = range(3)\n",
    "# recall_1_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb38d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4677, 2232], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get new score distribution\n",
    "score = df_score['newTremorLabel_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "# score distribution\n",
    "counts, bin_edges = np.histogram(score,bins = bin_range)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(score, bins = bin_range, histtype='bar', color = 'grey')\n",
    "ax.set_xlabel(title_name)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks(xtick_name)\n",
    "# save figure\n",
    "# plt.savefig(os.path.join(save_path,\"Tremor_score_distribution\"))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0ab3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbeff040",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35aaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "varThreshold = 0.0001\n",
    "# Remove features with zero variance\n",
    "df_sensor_feature = pdVarianceThreshold(df_sensor_feature,varThreshold)\n",
    "df_clinical_feature = pdVarianceThreshold(df_clinical_feature,varThreshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a959d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x__ar_coefficient__k_10__coeff_2', 'x__ar_coefficient__k_10__coeff_3',\n",
       "       'x__ar_coefficient__k_10__coeff_4', 'x__has_duplicate',\n",
       "       'x__percentage_of_reoccurring_datapoints_to_all_datapoints',\n",
       "       'x__percentage_of_reoccurring_values_to_all_values',\n",
       "       'x__ratio_value_number_to_time_series_length',\n",
       "       'x__sum_of_reoccurring_data_points', 'x__sum_of_reoccurring_values',\n",
       "       'y__percentage_of_reoccurring_datapoints_to_all_datapoints',\n",
       "       'y__percentage_of_reoccurring_values_to_all_values',\n",
       "       'y__ratio_value_number_to_time_series_length',\n",
       "       'z__ar_coefficient__k_10__coeff_2', 'z__ar_coefficient__k_10__coeff_3',\n",
       "       'z__ar_coefficient__k_10__coeff_4', 'z__partial_autocorrelation__lag_4',\n",
       "       'z__percentage_of_reoccurring_datapoints_to_all_datapoints',\n",
       "       'z__percentage_of_reoccurring_values_to_all_values',\n",
       "       'z__quantile__q_0.2', 'z__ratio_value_number_to_time_series_length'],\n",
       "      dtype='object', name='variable')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All dataset\n",
    "df_selected_sensor_all = pdSelectKBest(df_sensor_feature,score, f_classif, 20)\n",
    "df_selected_sensor_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd83194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split\n",
    "subject_id = df_score['subject_id']\n",
    "X_train_valid, y_train_valid, X_train, y_train,  X_valid, y_valid, X_test, y_test = train_val_test_split(df_selected_sensor_all, score, subject_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ad67d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yiting\\Anaconda3\\envs\\ws4pd\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 688  692  693 2093] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\Yiting\\Anaconda3\\envs\\ws4pd\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Train dataset\n",
    "# Train/Validation/Test Split\n",
    "subject_id = df_score['subject_id']\n",
    "X_train_valid, y_train_valid, X_train, y_train,  X_valid, y_valid, X_test, y_test = train_val_test_split(df_sensor_feature, score, subject_id)\n",
    "\n",
    "X_train_sf = pdSelectKBest(X_train, y_train, f_classif, 20)\n",
    "sf_index = X_train_sf.columns\n",
    "X_valid_sf = X_valid.loc[:,sf_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0df12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sensor_feature: numerical input\n",
    "# df_clinical_feature: categorical input\n",
    "# score: categorical output\n",
    "\n",
    "\n",
    "# SelectKBest\n",
    "df_selected_sensor = pdSelectKBest(df_sensor_feature,score, f_classif, 20)\n",
    "df_selected_clinical = pdSelectKBest(df_clinical_feature,score, chi2, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_sensor.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c82456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sensor features with clinical features\n",
    "df = pd.concat([df_sensor_feature, df_clinical_feature], axis=1) \n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Train/Validation/Test Split\n",
    "subject_id = df_score['subject_id']\n",
    "X_train_valid, y_train_valid, X_train, y_train,  X_valid, y_valid, X_test, y_test = train_val_test_split(df, score, subject_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a85b2a",
   "metadata": {},
   "source": [
    "# tsfresh builtin feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsfresh builtin feature selection \n",
    "X_selected = select_features(X_train, y_train)\n",
    "selected_features = X_selected.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10273e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6dca86",
   "metadata": {},
   "source": [
    "# Univariant selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariant selection\n",
    "df3 = pdSelectKBest(X_selected,y_train,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d86085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adaa415",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_selected,y_train)\n",
    "# print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X_selected.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance using Random Forest\n",
    "# evaluation of a model using 5 features chosen with random forest importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "# feature selection function\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=1000), max_features=10)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    " \n",
    "# feature selection\n",
    "X_train_fs, X_valid_fs, fs = select_features(X_train, y_train, X_valid)\n",
    "# fit the model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train_fs, y_train)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_valid_fs)\n",
    "\n",
    "# evaluate predictions\n",
    "F1_micro = f1_score(y_valid, y_pred, average = 'micro').round(2)\n",
    "print('F1 score: %.2f' % (F1_micro*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cef420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa2cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a492b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297a4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "classifiers = {\n",
    "    \"LogisticRegression\" : LogisticRegression(random_state=0, solver = 'liblinear'),\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "#     \"SVC\" : SVC(random_state=0, probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=0),\n",
    "    \"XGBoost\" : XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss'), # XGBoost takes too long\n",
    "    \"LGBM\" : LGBMClassifier(random_state=0),\n",
    "#     \"CatBoost\" : CatBoostClassifier(random_state=0, verbose=False),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Grids for grid search\n",
    "LR_grid = {'penalty': ['l1','l2'],\n",
    "           'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "           'max_iter': [50, 100, 150, 200, 250]}\n",
    "\n",
    "KNN_grid = {'n_neighbors': [3, 5, 7, 9],\n",
    "            'p': [1, 2]}\n",
    "\n",
    "# SVC_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "#             'kernel': ['linear', 'rbf'],\n",
    "#             'gamma': ['scale', 'auto']}\n",
    "\n",
    "RF_grid = {'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "        'max_depth': [2, 4, 6, 8, 10, 12]}\n",
    "\n",
    "boosted_grid = {'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [4, 8, 12],\n",
    "        'learning_rate': [0.05, 0.1, 0.15]}\n",
    "\n",
    "NB_grid={'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7]}\n",
    "\n",
    "# Dictionary of all grids\n",
    "grid = {\n",
    "    \"LogisticRegression\" : LR_grid,\n",
    "    \"KNN\" : KNN_grid,\n",
    "#     \"SVC\" : SVC_grid,\n",
    "    \"RandomForest\" : RF_grid,\n",
    "    \"XGBoost\" : boosted_grid,\n",
    "    \"LGBM\" : boosted_grid,\n",
    "#     \"CatBoost\" : boosted_grid,\n",
    "    \"NaiveBayes\": NB_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e458fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Training time (mins): 0.13\n",
      "\n",
      "Model: KNN\n",
      "Training time (mins): 0.02\n",
      "\n",
      "Model: RandomForest\n",
      "Training time (mins): 0.39\n",
      "\n",
      "Model: XGBoost\n",
      "Training time (mins): 0.78\n",
      "\n",
      "Model: LGBM\n",
      "Training time (mins): 0.12\n",
      "\n",
      "Model: NaiveBayes\n",
      "Training time (mins): 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier evaluation\n",
    "i=0\n",
    "clf_best_params=classifiers.copy()\n",
    "valid_scores=pd.DataFrame({'Classifer':classifiers.keys(),\n",
    "                           'Accuracy': np.zeros(len(classifiers)),\n",
    "                           'F1_macro': np.zeros(len(classifiers)),\n",
    "                           'F1_micro': np.zeros(len(classifiers)),\n",
    "                           'F1_weighted': np.zeros(len(classifiers)),\n",
    "                           'F1_0': np.zeros(len(classifiers)),\n",
    "                           'F1_1': np.zeros(len(classifiers)),                               \n",
    "                           'Precision_0': np.zeros(len(classifiers)),\n",
    "                           'Precision_1': np.zeros(len(classifiers)),\n",
    "                           'Recall_0': np.zeros(len(classifiers)),\n",
    "                           'Recall_1': np.zeros(len(classifiers)),\n",
    "                           'Training time': np.zeros(len(classifiers))})\n",
    "for key, classifier in classifiers.items():\n",
    "    start = time.time()\n",
    "    clf = GridSearchCV(estimator=classifier, param_grid=grid[key], n_jobs=-1, cv=None)\n",
    "\n",
    "    # Train and score\n",
    "    clf.fit(X_train_sf, y_train)\n",
    "    y_pred = clf.predict(X_valid_sf)\n",
    "    Accuracy = accuracy_score(y_valid, y_pred).round(2)\n",
    "    F1_macro = f1_score(y_valid, y_pred, average = 'macro').round(2)\n",
    "    F1_micro = f1_score(y_valid, y_pred, average = 'micro').round(2)\n",
    "    F1_weighted = f1_score(y_valid, y_pred, average = 'weighted').round(2)\n",
    "    F1_class = f1_score(y_valid, y_pred, average = None).round(2)\n",
    "    Precision = precision_score(y_valid, y_pred, average = None).round(2)\n",
    "    Recall = recall_score(y_valid, y_pred, average = None).round(2)                                         \n",
    "\n",
    "    valid_scores.iloc[i,1]=Accuracy\n",
    "    valid_scores.iloc[i,2]=F1_macro\n",
    "    valid_scores.iloc[i,3]=F1_micro\n",
    "    valid_scores.iloc[i,4]=F1_weighted\n",
    "    valid_scores.iloc[i,5]=F1_class[0]\n",
    "    valid_scores.iloc[i,6]=F1_class[1]\n",
    "    valid_scores.iloc[i,7]=Precision[0]\n",
    "    valid_scores.iloc[i,8]=Precision[1] \n",
    "    valid_scores.iloc[i,9]=Recall[0]\n",
    "    valid_scores.iloc[i,10]=Recall[1]\n",
    "\n",
    "    # Save trained model\n",
    "    clf_best_params[key]=clf.best_params_\n",
    "\n",
    "    # Print iteration and training time\n",
    "    stop = time.time()\n",
    "    valid_scores.iloc[i,11]=np.round((stop - start)/60, 2)\n",
    "\n",
    "\n",
    "    print('Model:', key)\n",
    "    print('Training time (mins):', valid_scores.iloc[i,11])\n",
    "    print('')\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23491c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifer  Accuracy  F1_macro  F1_micro  F1_weighted  F1_0  F1_1  \\\n",
       "0  LogisticRegression      0.70      0.64      0.70         0.68  0.79  0.48   \n",
       "1                 KNN      0.68      0.63      0.68         0.68  0.77  0.49   \n",
       "2        RandomForest      0.75      0.72      0.75         0.75  0.81  0.62   \n",
       "3             XGBoost      0.75      0.71      0.75         0.75  0.81  0.61   \n",
       "4                LGBM      0.74      0.70      0.74         0.74  0.81  0.60   \n",
       "5          NaiveBayes      0.72      0.69      0.72         0.72  0.79  0.59   \n",
       "\n",
       "   Precision_0  Precision_1  Recall_0  Recall_1  Training time  \n",
       "0         0.74         0.58      0.84      0.42           0.13  \n",
       "1         0.74         0.54      0.81      0.45           0.02  \n",
       "2         0.80         0.63      0.82      0.61           0.39  \n",
       "3         0.80         0.64      0.83      0.59           0.78  \n",
       "4         0.79         0.64      0.83      0.56           0.12  \n",
       "5         0.79         0.59      0.79      0.58           0.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "711cb553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n"
     ]
    }
   ],
   "source": [
    "best_clf_summary = SelectBestClf(valid_scores, recall_1_threshold, clf_best_params)\n",
    "best_clf = best_clf_summary[2]\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9f6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7951f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae3161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76799ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00515680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234ca50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "# Combine sensor features with clinical features\n",
    "df = pd.concat([df_sensor_feature, df_clinical_feature], axis=1) \n",
    "# Get scores\n",
    "score = df_score['newTremorLabel_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "## Set parameters\n",
    "varThreshold = 0.0001\n",
    "k_num = 20\n",
    "\n",
    "## Feature selection\n",
    "# Remove features with nan\n",
    "df2 = df.dropna(axis=1)\n",
    "\n",
    "# Remove features with zero variance\n",
    "df3 = pdVarianceThreshold(df2,varThreshold)\n",
    "\n",
    "# Univariant selection\n",
    "df4 = pdSelectKBest(df3,score,k_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaadb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
