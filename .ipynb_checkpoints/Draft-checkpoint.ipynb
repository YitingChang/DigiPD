{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0fa2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction import extract_features, MinimalFCParameters, EfficientFCParameters\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from numpy import set_printoptions\n",
    "from numpy.random import permutation\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import compress\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a13f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"E:\\\\WS4PD_data\"\n",
    "os.chdir(direc)\n",
    "save_path = os.path.join(direc, \"Figures\", \"Data_exploration\", \"GENEActiv_tremor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149737b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load score data\n",
    "score_file_path = os.path.join(direc, 'Feature_extraction','score_by_device.pkl')\n",
    "df_score = pd.read_pickle(score_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1228c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_score.shape)\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8afc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dyskinesia score distribution\n",
    "device_hand = ['dyskinesia_GENEActivHand', 'dyskinesia_PebbleHand']\n",
    "fig, axs = plt.subplots(figsize=(5,10),nrows=2, ncols=1)\n",
    "for i, hand in enumerate(device_hand):\n",
    "    score = df_score[hand]\n",
    "    axs[i].hist(score, histtype='bar', color = 'grey')\n",
    "    axs[i].set_ylabel('Count')\n",
    "    axs[i].set_xticks([0,1])\n",
    "    axs[i].set_title(hand)\n",
    "\n",
    "# save figure\n",
    "plt.savefig(os.path.join(save_path,\"Dyskinesia_distribution_device\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tremor score distribution\n",
    "device_hand = ['tremor_GENEActivHand', 'tremor_PebbleHand']\n",
    "fig, axs = plt.subplots(figsize=(5,10),nrows=2, ncols=1)\n",
    "for i, hand in enumerate(device_hand):\n",
    "    score = df_score[hand].astype(int)\n",
    "    axs[i].hist(score, histtype='bar', color = 'grey', density = True,\n",
    "                bins=np.arange(min(score), max(score) + 1, 1))\n",
    "    axs[i].set_xlabel('Tremor score')\n",
    "    axs[i].set_ylabel('Ratio')\n",
    "    axs[i].set_xticks([0,1,2,3,4])\n",
    "    axs[i].set_title(hand)\n",
    "\n",
    "# save figure\n",
    "plt.savefig(os.path.join(save_path,\"Tremor_score_distribution_device\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ef667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0126a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature data\n",
    "subject_ids = df_score.subject_id.unique()\n",
    "df_feature = pd.DataFrame()\n",
    "device = 'GENEActiv'\n",
    "for sb in subject_ids:\n",
    "    feature_file_path = os.path.join(direc,'Feature_extraction',device,sb + '_features.pkl')\n",
    "    df_feature_sb = pd.read_pickle(feature_file_path)\n",
    "    df_feature = pd.concat([df_feature,df_feature_sb])\n",
    "df_feature = df_feature.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2df88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_feature.shape)\n",
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e2ab2",
   "metadata": {},
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "score = df_score['tremor_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "# score distribution\n",
    "counts, bin_edges = np.histogram(score,bins = range(6))\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(score, histtype='bar', color = 'grey')\n",
    "ax.set_xlabel('Tremor score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([0,1,2,3,4])\n",
    "# save figure\n",
    "# plt.savefig(os.path.join(save_path,\"Tremor_score_distribution\"))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge score 3 and 4\n",
    "score[score==4] = 3\n",
    "df_score[df_score['tremor_GENEActivHand']==4]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302290d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling by copying minority class instances\n",
    "\n",
    "upsampled_df_feature = pd.DataFrame()\n",
    "upsampled_df_score = pd.DataFrame()\n",
    "upsample_size = 300\n",
    "# upsample_size = round(max(counts)/2)\n",
    "for c,s in zip(counts[0:4],range(4)):\n",
    "    \n",
    "    if s == 3:\n",
    "        df_feature_group = df_feature.loc[score==s]\n",
    "        df_score_group = df_score.loc[score==s]\n",
    "        idx_list = df_feature_group.index.tolist()\n",
    "        resample_idx = resample(idx_list, replace=True, n_samples=upsample_size, random_state=27)\n",
    "        upsampled_feature_group = df_feature_group.loc[resample_idx]\n",
    "        upsampled_score_group = df_score_group.loc[resample_idx]\n",
    "    else:\n",
    "        upsampled_feature_group = df_feature.loc[score==s]\n",
    "        upsampled_score_group = df_score.loc[score==s]\n",
    "        \n",
    "#     if c == max(counts):\n",
    "#         upsampled_feature_group = df_feature.loc[score==s]\n",
    "#         upsampled_score_group = df_score.loc[score==s]\n",
    "#     else:\n",
    "#         df_feature_group = df_feature.loc[score==s]\n",
    "#         df_score_group = df_score.loc[score==s]\n",
    "#         idx_list = df_feature_group.index.tolist()\n",
    "#         resample_idx = resample(idx_list, replace=True, n_samples=upsample_size, random_state=27)\n",
    "#         upsampled_feature_group = df_feature_group.loc[resample_idx]\n",
    "#         upsampled_score_group = df_score_group.loc[resample_idx]\n",
    "\n",
    "    upsampled_df_feature = pd.concat([upsampled_df_feature, upsampled_feature_group])\n",
    "    upsampled_df_score = pd.concat([upsampled_df_score, upsampled_score_group])\n",
    "\n",
    "    \n",
    "upsampled_df_feature = upsampled_df_feature.reset_index(drop=True)\n",
    "upsampled_df_score = upsampled_df_score.reset_index(drop=True)\n",
    "   \n",
    "print('upsampled features:' + str(upsampled_df_feature.shape))\n",
    "print('upsampled scores:' + str(upsampled_df_score.shape))\n",
    "\n",
    "# Try other upsmapling methods:\n",
    "# from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different task categories\n",
    "# task categories\n",
    "task_groups = [['stndg', 'sittg'],['wlkgs', 'wlkgc', 'wlkgp', 'strsu', 'strsd', 'ststd'],\n",
    "               ['ftnr', 'ftnl', 'ramr', 'raml', 'drawg', 'typng', 'ntblt', 'drnkg', 'orgpa', 'fldng'],\n",
    "              ['stndg', 'sittg', 'wlkgs', 'wlkgc', 'wlkgp', 'strsu', 'strsd', 'ststd',\n",
    "              'ftnr', 'ftnl', 'ramr', 'raml', 'drawg', 'typng', 'ntblt', 'drnkg', 'orgpa', 'fldng']]\n",
    "task_group_names = ['no_voluntary_movement','whole_body_movement', 'upperlimb_movement', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test datasets\n",
    "\n",
    "# train:validation:test = 0.5:0.25:0.25\n",
    "sb_train = ['6_BOS', '16_BOS', '7_NYC', '14_BOS', '8_NYC', '5_BOS', '12_NYC', '6_NYC', '17_BOS',\n",
    "           '4_BOS', '11_BOS', '10_BOS', '15_BOS', '4_NYC', '11_NYC']\n",
    "sb_val = ['8_BOS', '18_BOS', '2_NYC', '9_NYC', '3_BOS', '9_BOS']\n",
    "sb_test = ['19_BOS', '3_NYC', '7_BOS', '5_NYC', '13_BOS', '10_NYC', '12_BOS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380452f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "is_train = upsampled_df_score['subject_id'].isin(sb_train).tolist()\n",
    "is_val = upsampled_df_score['subject_id'].isin(sb_val).tolist()\n",
    "is_test = upsampled_df_score['subject_id'].isin(sb_test).tolist()\n",
    "\n",
    "df_feature_train = upsampled_df_feature[is_train]\n",
    "df_score_train = upsampled_df_score[is_train]\n",
    "df_feature_val = upsampled_df_feature[is_val]\n",
    "df_score_val = upsampled_df_score[is_val]\n",
    "df_feature_test = upsampled_df_feature[is_test]\n",
    "df_score_test = upsampled_df_score[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f055bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# hyper = [30, 50, 100, 150 , 200] #- choose 100\n",
    "# nPC = [3, 10, 30, 50, 100]- choose 30\n",
    "# tree_depth = [None, 2, 5 , 10]- choose None max_depth\n",
    "# tree_number = [30, 50, 100, 200, 300]- doesn't matter, use default 100 n_estimators\n",
    "# criterion_algo = ['gini', 'entropy'] - doesn't matter, use default gini criterion\n",
    "# min_samples_split = [2, 5, 10, 20] - doesn't matter, use default 2 min_samples_split\n",
    "# max_features = ['sqrt', 'log2', None] - doesn't matter, use default sqrt max_features\n",
    "\n",
    "# hyper = ['sqrt', 'log2', None] # max_features\n",
    "# accuracy = np.zeros([len(hyper),len(task_groups)])\n",
    "accuracy = np.zeros([1,len(task_groups)])\n",
    "for t,task,task_name in zip(range(len(task_groups)),task_groups, task_group_names):\n",
    "    is_tasks = upsampled_df_score['task_code'].isin(task).tolist()\n",
    "    df_feature_task = upsampled_df_feature[is_tasks]\n",
    "    df_score_task = upsampled_df_score[is_tasks]\n",
    "    \n",
    "    # Remove features with nan\n",
    "    df_feature2 = df_feature_task.dropna(axis=1)\n",
    "    \n",
    "    # Remove features with zero variance\n",
    "    sel = VarianceThreshold(threshold=0.0001)\n",
    "    df_feature3 = sel.fit_transform(df_feature2)\n",
    "    filter3 = sel.get_support()\n",
    "    feature_names2 = df_feature2.columns\n",
    "    feature_names3 = feature_names2[filter3]\n",
    "    df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "    \n",
    "    # Get scores\n",
    "    score = df_score_task['tremor_GENEActivHand'].values\n",
    "    score = np.array(score, dtype=float)\n",
    "\n",
    "#     for i,d in zip(range(len(hyper)), hyper):\n",
    "        # Univariate Selection\n",
    "    test = SelectKBest(score_func=f_classif, k=100)\n",
    "    df_feature4 = test.fit_transform(df_feature3, score)\n",
    "    filter4 = test.get_support()\n",
    "    feature_names4 = feature_names3[filter4]\n",
    "    df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "\n",
    "    # PCA\n",
    "    X=df_feature4.values\n",
    "    pca = PCA(n_components=30)\n",
    "    X_new = pca.fit_transform(X)\n",
    "\n",
    "    # Random Forest\n",
    "    # Tuning hyperparameters\n",
    "    # train/validation split\n",
    "    is_train_task = list(compress(is_train,is_tasks))\n",
    "    is_val_task = list(compress(is_val,is_tasks))\n",
    "    X_train = X_new[is_train_task,:]\n",
    "    y_train = score[is_train_task]\n",
    "    X_val = X_new[is_val_task,:]\n",
    "    y_val = score[is_val_task]\n",
    "\n",
    "    #     for i,d in zip(range(len(hyper)), hyper):\n",
    "    clf = RandomForestClassifier(max_depth = None, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_accuracy = round(clf.score(X_val, y_val)*100,1)\n",
    "    accuracy[0][t] = model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21999321",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(data=accuracy, columns=task_group_names)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186157d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b646e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc87c2e4",
   "metadata": {},
   "source": [
    "# No up- or down- sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different task categories\n",
    "# task categories\n",
    "task_groups = [['stndg', 'sittg'],['wlkgs', 'wlkgc', 'wlkgp', 'strsu', 'strsd', 'ststd'],\n",
    "               ['ftnr', 'ftnl', 'ramr', 'raml', 'drawg', 'typng', 'ntblt', 'drnkg', 'orgpa', 'fldng'],\n",
    "              ['stndg', 'sittg', 'wlkgs', 'wlkgc', 'wlkgp', 'strsu', 'strsd', 'ststd',\n",
    "              'ftnr', 'ftnl', 'ramr', 'raml', 'drawg', 'typng', 'ntblt', 'drnkg', 'orgpa', 'fldng']]\n",
    "task_group_names = ['no_voluntary_movement','whole_body_movement', 'upperlimb_movement', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test datasets\n",
    "\n",
    "# train:validation:test = 0.5:0.25:0.25\n",
    "sb_train = ['6_BOS', '16_BOS', '7_NYC', '14_BOS', '8_NYC', '5_BOS', '12_NYC', '6_NYC', '17_BOS',\n",
    "           '4_BOS', '11_BOS', '10_BOS', '15_BOS', '4_NYC', '11_NYC']\n",
    "sb_val = ['8_BOS', '18_BOS', '2_NYC', '9_NYC', '3_BOS', '9_BOS']\n",
    "sb_test = ['19_BOS', '3_NYC', '7_BOS', '5_NYC', '13_BOS', '10_NYC', '12_BOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "is_train = df_score['subject_id'].isin(sb_train).tolist()\n",
    "is_val = df_score['subject_id'].isin(sb_val).tolist()\n",
    "is_test = df_score['subject_id'].isin(sb_test).tolist()\n",
    "\n",
    "df_feature_train = df_feature[is_train]\n",
    "df_score_train = df_score[is_train]\n",
    "df_feature_val = df_feature[is_val]\n",
    "df_score_val = df_score[is_val]\n",
    "df_feature_test = df_feature[is_test]\n",
    "df_score_test = df_score[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# kbest = [30, 50, 100, 150 , 200]- choose 100\n",
    "# nPC = [3, 10, 30, 50, 100]- choose 30\n",
    "# tree_depth = [None, 2, 5 , 10]- choose None max_depth\n",
    "# tree_number = [30, 50, 100, 200, 300]- doesn't matter, use default 100 n_estimators\n",
    "# criterion_algo = ['gini', 'entropy'] - doesn't matter, use default gini criterion\n",
    "# min_samples_split = [2, 5, 10, 20] - doesn't matter, use default 2 min_samples_split\n",
    "# max_features = ['sqrt', 'log2', None] - doesn't matter, use default sqrt max_features\n",
    "\n",
    "# hyper = ['sqrt', 'log2', None] # max_features\n",
    "# accuracy = np.zeros([len(hyper),len(task_groups)])\n",
    "accuracy = np.zeros([1,len(task_groups)])\n",
    "\n",
    "for t,task,task_name in zip(range(len(task_groups)),task_groups, task_group_names):\n",
    "    is_tasks = df_score['task_code'].isin(task).tolist()\n",
    "    df_feature_task = df_feature[is_tasks]\n",
    "    df_score_task = df_score[is_tasks]\n",
    "    \n",
    "    # Remove features with nan\n",
    "    df_feature2 = df_feature_task.dropna(axis=1)\n",
    "    \n",
    "    # Remove features with zero variance\n",
    "    sel = VarianceThreshold(threshold=0.0001)\n",
    "    df_feature3 = sel.fit_transform(df_feature2)\n",
    "    filter3 = sel.get_support()\n",
    "    feature_names2 = df_feature2.columns\n",
    "    feature_names3 = feature_names2[filter3]\n",
    "    df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "    \n",
    "    # Get scores\n",
    "    score = df_score_task['dyskinesia_PebbleHand']\n",
    "#     score = df_score_task['tremor_GENEActivHand'].values\n",
    "#     score = np.array(score, dtype=float)\n",
    "    \n",
    "#     Merge score 3 and 4\n",
    "#     score[score==4] = 3\n",
    "    \n",
    "    # Univariate Selection\n",
    "    test = SelectKBest(score_func=f_classif, k=100)\n",
    "    df_feature4 = test.fit_transform(df_feature3, score)\n",
    "    filter4 = test.get_support()\n",
    "    feature_names4 = feature_names3[filter4]\n",
    "    df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "    \n",
    "    # PCA\n",
    "    X=df_feature4.values\n",
    "    pca = PCA(n_components=30)\n",
    "    X_new = pca.fit_transform(X)\n",
    "\n",
    "    # Random Forest\n",
    "    # Tuning hyperparameters\n",
    "    # train/validation split\n",
    "    is_train_task = list(compress(is_train,is_tasks))\n",
    "    is_val_task = list(compress(is_val,is_tasks))\n",
    "    X_train = X_new[is_train_task,:]\n",
    "    y_train = score[is_train_task]\n",
    "    X_val = X_new[is_val_task,:]\n",
    "    y_val = score[is_val_task]\n",
    "    \n",
    "#     for i,d in zip(range(len(hyper)), hyper):\n",
    "    clf = RandomForestClassifier(max_depth = None, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_accuracy = round(clf.score(X_val, y_val)*100,1)\n",
    "#     accuracy[i][t] = model_accuracy\n",
    "    accuracy[0][t] = model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5561d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(data=accuracy, columns=task_group_names)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.zeros([1,len(task_groups)])\n",
    "\n",
    "for t,task,task_name in zip(range(len(task_groups)),task_groups, task_group_names):\n",
    "    is_tasks = df_score['task_code'].isin(task).tolist()\n",
    "    df_feature_task = df_feature[is_tasks]\n",
    "    df_score_task = df_score[is_tasks]\n",
    "    \n",
    "    # Remove features with nan\n",
    "    df_feature2 = df_feature_task.dropna(axis=1)\n",
    "    \n",
    "    # Remove features with zero variance\n",
    "    sel = VarianceThreshold(threshold=0.0001)\n",
    "    df_feature3 = sel.fit_transform(df_feature2)\n",
    "    filter3 = sel.get_support()\n",
    "    feature_names2 = df_feature2.columns\n",
    "    feature_names3 = feature_names2[filter3]\n",
    "    df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "    \n",
    "    # Get scores\n",
    "    score = df_score_task['tremor_PebbleHand'].values\n",
    "    score = np.array(score, dtype=float)\n",
    "    \n",
    "    # Merge score 3 and 4\n",
    "    score[score==4] = 3\n",
    "    \n",
    "    # Univariate Selection\n",
    "    test = SelectKBest(score_func=f_classif, k=100)\n",
    "    df_feature4 = test.fit_transform(df_feature3, score)\n",
    "    filter4 = test.get_support()\n",
    "    feature_names4 = feature_names3[filter4]\n",
    "    df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "    \n",
    "    # PCA\n",
    "    X=df_feature4.values\n",
    "    pca = PCA(n_components=30)\n",
    "    X_new = pca.fit_transform(X)\n",
    "\n",
    "    # Random Forest\n",
    "    # Tuning hyperparameters\n",
    "    # train/test split\n",
    "    is_train_task = list(compress(is_train,is_tasks))\n",
    "    is_test_task = list(compress(is_test,is_tasks))\n",
    "    X_train = X_new[is_train_task,:]\n",
    "    y_train = score[is_train_task]\n",
    "    X_test = X_new[is_test_task,:]\n",
    "    y_test = score[is_test_task]\n",
    "    \n",
    "#     for i,d in zip(range(len(hyper)), hyper):\n",
    "    clf = RandomForestClassifier(max_depth = None, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_accuracy = round(clf.score(X_test, y_test)*100,1)\n",
    "#     accuracy[i][t] = model_accuracy\n",
    "    accuracy[0][t] = model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(data=accuracy, columns=task_group_names)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafeb557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a61574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedc886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b595d6e",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task,task_name in zip(task_groups, task_group_names):\n",
    "    is_tasks = df_score['task_code'].isin(task).tolist()\n",
    "    df_feature_task = df_feature[is_tasks]\n",
    "    df_score_task = df_score[is_tasks]\n",
    "    \n",
    "    # Remove features with nan\n",
    "    df_feature2 = df_feature_task.dropna(axis=1)\n",
    "    \n",
    "    # Remove features with zero variance\n",
    "    sel = VarianceThreshold(threshold=0.0001)\n",
    "    df_feature3 = sel.fit_transform(df_feature2)\n",
    "    filter3 = sel.get_support()\n",
    "    feature_names2 = df_feature2.columns\n",
    "    feature_names3 = feature_names2[filter3]\n",
    "    df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "\n",
    "    \n",
    "    # Univariate Selection\n",
    "    test = SelectKBest(score_func=f_classif, k=50)\n",
    "    df_feature4 = test.fit_transform(df_feature3, score)\n",
    "    filter4 = test.get_support()\n",
    "    feature_names4 = feature_names3[filter4]\n",
    "    df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "    \n",
    "    # PCA\n",
    "    X=df_feature3.values\n",
    "    pca = PCA(n_components=10)\n",
    "    fit = pca.fit(X)\n",
    "    cumulative_EV = np.cumsum(fit.explained_variance_ratio_)\n",
    "    \n",
    "    X_new = pca.fit_transform(X)\n",
    "    PC1 = X_new[:,0]\n",
    "    x = PC1\n",
    "    y = score\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x,y,facecolors='none', edgecolors='b')\n",
    "    ax.set_xlabel('PC1' + '(' + str(round(cumulative_EV[0],2)*100) + '%)')\n",
    "    ax.set_ylabel('Tremor score')\n",
    "    ax.set_yticks([0,1,2,3])\n",
    "    ax.set_yticklabels(['0','1','2','3/4'])\n",
    "    ax.set_title(task_name)\n",
    "    \n",
    "    # save figure\n",
    "    file_name = 'PC1' + '_' + task_name\n",
    "    plt.savefig(os.path.join(save_path,'PCA_50', file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects in the training dataset\n",
    "# train:test = 0.67:0.33\n",
    "# sb_train = ['11_NYC', '6_BOS', '8_BOS', '2_NYC', '7_NYC', '5_BOS', '11_BOS', '15_BOS', '4_NYC',\n",
    "#                 '12_NYC', '6_NYC', '3_BOS', '14_BOS', '18_BOS', '9_NYC', '4_BOS', '9_BOS', '16_BOS']\n",
    "\n",
    "# # train:test = 0.75:0.25\n",
    "# sb_train = ['8_BOS', '11_NYC', '2_NYC', '9_NYC', '3_BOS', '8_NYC', '7_NYC', '18_BOS', '15_BOS',\n",
    "#            '4_NYC', '12_NYC', '9_BOS', '6_NYC', '6_BOS', '16_BOS', '5_BOS', '14_BOS', '4_BOS',\n",
    "#            '11_BOS', '10_BOS', '17_BOS']\n",
    "# is_test_sb = ~np.isin(subject_ids, sb_train)\n",
    "# sb_test = subject_ids[is_test_sb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f60a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with nan\n",
    "df_feature2 = df_feature.dropna(axis=1)\n",
    "\n",
    "# Remove features with zero variance\n",
    "sel = VarianceThreshold()\n",
    "df_feature3 = sel.fit_transform(df_feature2)\n",
    "filter3 = sel.get_support()\n",
    "feature_names2 = df_feature2.columns\n",
    "feature_names3 = feature_names2[filter3]\n",
    "df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "\n",
    "# Get scores\n",
    "score = df_score['tremor_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "# Merge score 3 and 4\n",
    "score[score==4] = 3\n",
    "\n",
    "# Univariate Selection\n",
    "test = SelectKBest(score_func=f_classif, k=100)\n",
    "df_feature4 = test.fit_transform(df_feature3, score)\n",
    "filter4 = test.get_support()\n",
    "feature_names4 = feature_names3[filter4]\n",
    "df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "\n",
    "# PCA\n",
    "X=df_feature4.values\n",
    "pca = PCA(n_components=10)\n",
    "X_new = pca.fit_transform(X)\n",
    "PC1 = X_new[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd69308",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_new[is_train,0:3]\n",
    "y_train = score[is_train]\n",
    "X_test = X_new[is_test,0:3]\n",
    "y_test = score[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941830c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=0,  oob_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "model_accuracy_train = round(clf.oob_score_,3)*100\n",
    "model_accuracy_test = round(clf.score(X_test, y_test),3)*100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
