{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5443b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions\n",
    "# 1. Can wearable sensor data predict tremor score? \n",
    "# 2. Can wearable sensor data predict whether tremor is present?\n",
    "# 3. Can wearable sensor data predict whether tremor symptom is sever (score>2)? \n",
    "\n",
    "# Using sensor data from the non-voluntary-movement task group can predict sever tremor well (up-sampling- max/2)\n",
    "\n",
    "# Metrics\n",
    "\n",
    "# Would gender, age, diagnosis history, motor task can help with model prediction?\n",
    "# If motor tasks affect model performance, should we predict motor tasks using sensor data first?\n",
    "# (Stacked models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45148b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import set_printoptions, sqrt, argmax, arange\n",
    "from numpy.random import permutation\n",
    "import scipy.stats as stats\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#tsfresh\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction import extract_features, MinimalFCParameters, EfficientFCParameters\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Self-defined functions\n",
    "from Utilities import pdVarianceThreshold, pdSelectKBest, train_val_test_split, upsampling, SelectBestClf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad8c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"E:\\\\WS4PD_data\"\n",
    "os.chdir(direc)\n",
    "save_path = os.path.join(direc, \"Model_validation\", \"GENEActiv_tremor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76488c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e914c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load score data\n",
    "score_file_path = os.path.join(direc, 'Feature_extraction','score_by_device.pkl')\n",
    "df_score = pd.read_pickle(score_file_path)\n",
    "\n",
    "# Tremor: merge score 3 and 4\n",
    "df_score['tremor_GENEActivHand'].loc[df_score['tremor_GENEActivHand']==4]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2abb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sensor feature data\n",
    "subject_ids = df_score.subject_id.unique()\n",
    "df_feature = pd.DataFrame()\n",
    "device = 'GENEActiv'\n",
    "for sb in subject_ids:\n",
    "    feature_file_path = os.path.join(direc,'Feature_extraction',device,sb + '_features.pkl')\n",
    "    df_feature_sb = pd.read_pickle(feature_file_path)\n",
    "    df_feature = pd.concat([df_feature,df_feature_sb])\n",
    "df_feature = df_feature.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e70192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6909, 69)\n"
     ]
    }
   ],
   "source": [
    "# load clinical features\n",
    "meta_file_path = os.path.join(direc, 'Feature_extraction','metadata_features.pkl')\n",
    "df_meta = pd.read_pickle(meta_file_path)\n",
    "\n",
    "# drop subject_id and task_code \n",
    "# df_meta.drop(columns = ['subject_id', 'task_code'])\n",
    "df_meta = df_meta.drop(columns = 'subject_id')\n",
    "\n",
    "# One-hot encoding clinical/ categorical features\n",
    "categorical_columns = df_meta.columns\n",
    "for column in categorical_columns:\n",
    "    tempdf = pd.get_dummies(df_meta[column], prefix=column)\n",
    "    df_meta = pd.merge(\n",
    "        left=df_meta,\n",
    "        right=tempdf,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    df_meta = df_meta.drop(columns=column)\n",
    "print(df_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23b173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new label for each question\n",
    "\n",
    "# Tremor\n",
    "# 1. Can wearable sensor data predict tremor score? \n",
    "# df_score['newTremorLabel_GENEActivHand'] = df_score['tremor_GENEActivHand']\n",
    "# title_name = 'Tremor score'\n",
    "# save_name = 'tremor_score'\n",
    "# xtick_name = [0,1,2,3,4]\n",
    "# bin_range = range(5)\n",
    "\n",
    "# 2. Can wearable sensor data predict whether tremor is present?\n",
    "is_tremor = df_score['tremor_GENEActivHand'].astype(int)>0\n",
    "df_score['newTremorLabel_GENEActivHand'] = np.nan\n",
    "df_score['newTremorLabel_GENEActivHand'].loc[is_tremor] = 1\n",
    "df_score['newTremorLabel_GENEActivHand'].loc[~is_tremor] = 0\n",
    "\n",
    "title_name = 'is tremor'\n",
    "save_name = 'is_tremor'\n",
    "xtick_name = [0,1]\n",
    "bin_range = range(3)\n",
    "recall_1_threshold = 0.8\n",
    "\n",
    "# 3. Can wearable sensor data predict whether tremor symptom is sever (score>2)? \n",
    "# is_sever_tremor = df_score['tremor_GENEActivHand'].astype(int)>2\n",
    "# df_score['newTremorLabel_GENEActivHand'] = np.nan\n",
    "# df_score['newTremorLabel_GENEActivHand'].loc[is_sever_tremor] = 1\n",
    "# df_score['newTremorLabel_GENEActivHand'].loc[~is_sever_tremor] = 0\n",
    "\n",
    "# title_name = 'is sever tremor (tremor score>2)'\n",
    "# save_name = 'is_sever_tremor'\n",
    "# xtick_name = [0,1]\n",
    "# bin_range = range(3)\n",
    "# recall_1_threshold = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53337ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test mild tremor after removing sever tremor\n",
    "# is_sever_tremor = df_score['tremor_GENEActivHand'].astype(int)>2\n",
    "# df_score = df_score.loc[~is_sever_tremor] \n",
    "# df_feature = df_feature.loc[~is_sever_tremor] \n",
    "# df_meta = df_meta.loc[~is_sever_tremor] \n",
    "# print(df_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79280ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4677, 2232], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPr0lEQVR4nO3df6zddX3H8eeLosCmbBAupGuZZVk1Aos4KqK4RWQL3Y8ILqJ1OmpC1oSxTefiAtsSwKyJS5bFYAauU0ZxRlKnG+iGihUkywhwUWYpSGhkQAehFbNYtqzS+t4f99P0WE7v57T0nHvb+3wkJ+f7fX8/n+95X9LkxffH+Z5UFZIkzeaouW5AkjT/GRaSpC7DQpLUZVhIkroMC0lS19Fz3cC4nHTSSbVs2bK5bkOSDisPPPDA96pqat/6ERsWy5YtY3p6eq7bkKTDSpInhtU9DSVJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeo6Yr/B/VJce+21c92CjmBXX331XLcgHTCPLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlr7GGRZFGSbyX5Uls/MckdSR5r7ycMjL0qyZYkjya5cKB+dpJNbdt1STLuviVJe03iyOIDwCMD61cCG6tqObCxrZPkdGAVcAawErg+yaI25wZgDbC8vVZOoG9JUjPWsEiyFPgN4JMD5YuA9W15PXDxQP2WqtpZVY8DW4BzkiwGjq+qe6qqgJsH5kiSJmDcRxYfA/4E+NFA7ZSqegagvZ/c6kuApwbGbW21JW153/qLJFmTZDrJ9Pbt2w/JHyBJGmNYJPlNYFtVPTDqlCG1mqX+4mLVuqpaUVUrpqamRvxYSVLP0WPc93nA25P8OnAscHySfwCeTbK4qp5pp5i2tfFbgVMH5i8Fnm71pUPqkqQJGduRRVVdVVVLq2oZMxeuv15V7wNuA1a3YauBW9vybcCqJMckOY2ZC9n3tVNVO5Kc2+6CunRgjiRpAsZ5ZLE/HwU2JLkMeBK4BKCqNifZADwM7AKuqKrdbc7lwE3AccDt7SVJmpCJhEVV3QXc1ZafAy7Yz7i1wNoh9WngzPF1KEmajd/gliR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1DW2sEhybJL7kvxHks1Jrm31E5PckeSx9n7CwJyrkmxJ8miSCwfqZyfZ1LZdlyTj6luS9GLjPLLYCbytql4HnAWsTHIucCWwsaqWAxvbOklOB1YBZwArgeuTLGr7ugFYAyxvr5Vj7FuStI+xhUXNeL6tvqy9CrgIWN/q64GL2/JFwC1VtbOqHge2AOckWQwcX1X3VFUBNw/MkSRNwFivWSRZlORBYBtwR1XdC5xSVc8AtPeT2/AlwFMD07e22pK2vG992OetSTKdZHr79u2H9G+RpIVsrGFRVbur6ixgKTNHCWfOMnzYdYiapT7s89ZV1YqqWjE1NXXA/UqShpvI3VBV9d/AXcxca3i2nVqivW9rw7YCpw5MWwo83epLh9QlSRMyzruhppL8dFs+DvgV4DvAbcDqNmw1cGtbvg1YleSYJKcxcyH7vnaqakeSc9tdUJcOzJEkTcDRY9z3YmB9u6PpKGBDVX0pyT3AhiSXAU8ClwBU1eYkG4CHgV3AFVW1u+3rcuAm4Djg9vaSJE3I2MKiqr4NvH5I/Tnggv3MWQusHVKfBma73iFJGiO/wS1J6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNVJYJDlvlJok6cg06pHFx0esSZKOQLN+KS/Jm4A3A1NJPjSw6Xhg0fBZkqQjTe8b3C8HXtHGvXKg/gPgneNqSpI0v8waFlX1DeAbSW6qqicm1JMkaZ4Z9dlQxyRZBywbnFNVbxtHU5Kk+WXUsPgc8Angk8DuzlhJ0hFm1LDYVVU3jLUTSdK8Neqts19M8ntJFic5cc9rrJ1JkuaNUY8s9vyy3YcHagX83KFtR5I0H40UFlV12rgbkSTNXyOFRZJLh9Wr6uZD244kaT4a9TTUGwaWj2XmZ1G/CRgWkrQAjHoa6g8G15P8FPDpsXQkSZp3DvYR5f8LLD+UjUiS5q9Rr1l8kZm7n2DmAYKvBTaMqylJ0vwy6jWLvxpY3gU8UVVbx9CPJGkeGuk0VHug4HeYefLsCcAPx9mUJGl+GfWX8t4F3AdcArwLuDeJjyiXpAVi1NNQfwa8oaq2ASSZAr4G/OO4GpMkzR+j3g111J6gaJ47gLmSpMPcqEcWX07yFeCzbf3dwL+OpyVJ0nzT+w3unwdOqaoPJ/kt4C1AgHuAz0ygP+mIc+211851CzqCXX311WPZb+9U0seAHQBV9YWq+lBV/REzRxUfG0tHkqR5pxcWy6rq2/sWq2qamZ9YlSQtAL2wOHaWbccdykYkSfNXLyzuT/K7+xaTXAY8MJ6WJEnzTe9uqA8C/5TkvewNhxXAy4F3jLEvSdI8MmtYVNWzwJuTnA+c2cr/UlVfH3tnkqR5Y9RnQ91ZVR9vr5GCIsmpSe5M8kiSzUk+0OonJrkjyWPt/YSBOVcl2ZLk0SQXDtTPTrKpbbsuSQ70D5UkHbxxfgt7F/DHVfVa4FzgiiSnA1cCG6tqObCxrdO2rQLOAFYC1ydZ1PZ1A7CGmd/QWN62S5ImZGxhUVXPVNU32/IO4BFgCXARsL4NWw9c3JYvAm6pqp1V9TiwBTgnyWLg+Kq6p6qKmZ9yvRhJ0sRM5PlOSZYBrwfuZeYb4c/ATKAAJ7dhS4CnBqZtbbUlbXnf+rDPWZNkOsn09u3bD+nfIEkL2djDIskrgM8DH6yqH8w2dEitZqm/uFi1rqpWVNWKqampA29WkjTUWMMiycuYCYrPVNUXWvnZdmqJ9r7nabZbgVMHpi8Fnm71pUPqkqQJGVtYtDuWPgU8UlV/PbDpNmB1W14N3DpQX5XkmCSnMXMh+752qmpHknPbPi8dmCNJmoBRH1F+MM4DfgfYlOTBVvtT4KPAhvYt8CeZ+fU9qmpzkg3Aw8zcSXVFVe1u8y4HbmLmESO3t5ckaULGFhZV9W8Mv94AcMF+5qwF1g6pT7P3S4GSpAnz1+4kSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1jS0sktyYZFuShwZqJya5I8lj7f2EgW1XJdmS5NEkFw7Uz06yqW27LknG1bMkabhxHlncBKzcp3YlsLGqlgMb2zpJTgdWAWe0OdcnWdTm3ACsAZa31777lCSN2djCoqruBr6/T/kiYH1bXg9cPFC/pap2VtXjwBbgnCSLgeOr6p6qKuDmgTmSpAmZ9DWLU6rqGYD2fnKrLwGeGhi3tdWWtOV965KkCZovF7iHXYeoWerDd5KsSTKdZHr79u2HrDlJWugmHRbPtlNLtPdtrb4VOHVg3FLg6VZfOqQ+VFWtq6oVVbViamrqkDYuSQvZpMPiNmB1W14N3DpQX5XkmCSnMXMh+752qmpHknPbXVCXDsyRJE3I0ePacZLPAm8FTkqyFbga+CiwIcllwJPAJQBVtTnJBuBhYBdwRVXtbru6nJk7q44Dbm8vSdIEjS0squo9+9l0wX7GrwXWDqlPA2cewtYkSQdovlzgliTNY4aFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrsMmLJKsTPJoki1JrpzrfiRpITkswiLJIuBvgF8DTgfek+T0ue1KkhaOwyIsgHOALVX13ar6IXALcNEc9yRJC8bRc93AiJYATw2sbwXeuO+gJGuANW31+SSPHuTnnQR87yDnSj3++9LYXHPNNS91F68aVjxcwiJDavWiQtU6YN1L/rBkuqpWvNT9SMP470uHo8PlNNRW4NSB9aXA03PUiyQtOIdLWNwPLE9yWpKXA6uA2+a4J0laMA6L01BVtSvJ7wNfARYBN1bV5jF+5Es+lSXNwn9fOuyk6kWn/iVJ+jGHy2koSdIcMiwkSV2GxQAfKaJxSnJjkm1JHprrXqQDZVg0PlJEE3ATsHKum5AOhmGxl48U0VhV1d3A9+e6D+lgGBZ7DXukyJI56kWS5hXDYq+RHikiSQuRYbGXjxSRpP0wLPbykSKStB+GRVNVu4A9jxR5BNgw5keKaIFJ8lngHuA1SbYmuWyue5JG5eM+JEldHllIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJBmkeTfD2DsB5P8xDj7keaKt85Kh0iS/wRWVNX3hmxbVFW7x/z5R7fvC0mHnEcW0iySPN/eFye5O8mDSR5K8kv7jPtD4GeAO5PcuWduko8kuRd4U5L3Jbmv7eNv22Px94z7yyQPJPlaknOS3JXku0ne3sYcm+Tvk2xK8q0k57f6+5N8LskXga9O7r+MFhrDQhrNbwNfqaqzgNcBDw5urKrrmHmW2PlVdX4r/yTwUFW9EXgOeDdwXtvHbuC9A+PuqqqzgR3AXwC/CrwD+Egbc0X7nF8A3gOsT3Js2/YmYHVVve0Q/r3Sjzl6rhuQDhP3AzcmeRnwz1X14AhzdgOfb8sXAGcD9ycBOA7Y1rb9EPhyW94E7KyqF5JsApa1+luAjwNU1XeSPAG8um27o6r8nQyNlUcW0gjaDxf9MvBfwKeTXDrCtP8buE4RYH1VndVer6mqa9q2F2rvxcMfATvbZ/6Ivf9DN+wR+nv8zwH8KdJBMSykESR5FbCtqv4O+BTwi0OG7QBeuZ9dbATemeTktr8T2z5HdTfttFWSVwM/Czx6APOll8TTUNJo3gp8OMkLwPPAsCOLdcDtSZ4ZuG4BQFU9nOTPga8mOQp4gZnrEE+M+PnXA59op6Z2Ae+vqp3tlJY0dt46K0nq8jSUJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnq+n/zHupH2h41TwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get new score distribution\n",
    "score = df_score['newTremorLabel_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "# score distribution\n",
    "counts, bin_edges = np.histogram(score,bins = bin_range)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(score, bins = bin_range, histtype='bar', color = 'grey')\n",
    "ax.set_xlabel(title_name)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks(xtick_name)\n",
    "# save figure\n",
    "# plt.savefig(os.path.join(save_path,\"Tremor_score_distribution\"))\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18adbdc",
   "metadata": {},
   "source": [
    "# Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_size = round(max(counts)/2)\n",
    "upsampled_df_score, upsampled_df_feature, upsampled_df_meta = upsampling(df_score, df_feature, df_meta, upsample_size, counts, score)\n",
    "print('upsampled features:' + str(upsampled_df_feature.shape))\n",
    "print('upsampled scores:' + str(upsampled_df_score.shape))\n",
    "print('upsampled meta:' + str(upsampled_df_meta.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd01783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = upsampled_df_feature\n",
    "df_score = upsampled_df_score\n",
    "df_meta = upsampled_df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797638ef",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdecae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "# Combine sensor features with clinical features\n",
    "df = pd.concat([df_feature, df_meta], axis=1) \n",
    "# Get scores\n",
    "score = df_score['newTremorLabel_GENEActivHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "## Set parameters\n",
    "varThreshold = 0.0001\n",
    "k_num = 10\n",
    "\n",
    "## Feature selection\n",
    "# Remove features with nan\n",
    "df2 = df.dropna(axis=1)\n",
    "\n",
    "# Remove features with zero variance\n",
    "df3 = pdVarianceThreshold(df2,varThreshold)\n",
    "\n",
    "# Univariant selection\n",
    "df4 = pdSelectKBest(df3,score,k_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4b859",
   "metadata": {},
   "source": [
    "# Select Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6620a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split\n",
    "subject_id = df_score['subject_id']\n",
    "X_train_valid, y_train_valid, X_train, y_train,  X_valid, y_valid, X_test, y_test = train_val_test_split(df4, score, subject_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0855b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "classifiers = {\n",
    "    \"LogisticRegression\" : LogisticRegression(random_state=0, solver = 'liblinear'),\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "#     \"SVC\" : SVC(random_state=0, probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=0),\n",
    "    \"XGBoost\" : XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss'), # XGBoost takes too long\n",
    "    \"LGBM\" : LGBMClassifier(random_state=0),\n",
    "#     \"CatBoost\" : CatBoostClassifier(random_state=0, verbose=False),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Grids for grid search\n",
    "LR_grid = {'penalty': ['l1','l2'],\n",
    "           'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "           'max_iter': [50, 100, 150, 200, 250]}\n",
    "\n",
    "KNN_grid = {'n_neighbors': [3, 5, 7, 9],\n",
    "            'p': [1, 2]}\n",
    "\n",
    "# SVC_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "#             'kernel': ['linear', 'rbf'],\n",
    "#             'gamma': ['scale', 'auto']}\n",
    "\n",
    "RF_grid = {'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "        'max_depth': [2, 4, 6, 8, 10, 12]}\n",
    "\n",
    "boosted_grid = {'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [4, 8, 12],\n",
    "        'learning_rate': [0.05, 0.1, 0.15]}\n",
    "\n",
    "NB_grid={'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7]}\n",
    "\n",
    "# Dictionary of all grids\n",
    "grid = {\n",
    "    \"LogisticRegression\" : LR_grid,\n",
    "    \"KNN\" : KNN_grid,\n",
    "#     \"SVC\" : SVC_grid,\n",
    "    \"RandomForest\" : RF_grid,\n",
    "    \"XGBoost\" : boosted_grid,\n",
    "    \"LGBM\" : boosted_grid,\n",
    "#     \"CatBoost\" : boosted_grid,\n",
    "    \"NaiveBayes\": NB_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f79c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Training time (mins): 0.12\n",
      "\n",
      "Model: KNN\n",
      "Training time (mins): 0.01\n",
      "\n",
      "Model: RandomForest\n",
      "Training time (mins): 0.28\n",
      "\n",
      "Model: XGBoost\n",
      "Training time (mins): 0.33\n",
      "\n",
      "Model: LGBM\n",
      "Training time (mins): 0.08\n",
      "\n",
      "Model: NaiveBayes\n",
      "Training time (mins): 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier evaluation\n",
    "i=0\n",
    "clf_best_params=classifiers.copy()\n",
    "valid_scores=pd.DataFrame({'Classifer':classifiers.keys(),\n",
    "                           'Accuracy': np.zeros(len(classifiers)),\n",
    "                           'F1_macro': np.zeros(len(classifiers)),\n",
    "                           'F1_micro': np.zeros(len(classifiers)),\n",
    "                           'F1_weighted': np.zeros(len(classifiers)),\n",
    "                           'F1_0': np.zeros(len(classifiers)),\n",
    "                           'F1_1': np.zeros(len(classifiers)),                               \n",
    "                           'Precision_0': np.zeros(len(classifiers)),\n",
    "                           'Precision_1': np.zeros(len(classifiers)),\n",
    "                           'Recall_0': np.zeros(len(classifiers)),\n",
    "                           'Recall_1': np.zeros(len(classifiers)),\n",
    "                           'Training time': np.zeros(len(classifiers))})\n",
    "for key, classifier in classifiers.items():\n",
    "    start = time.time()\n",
    "    clf = GridSearchCV(estimator=classifier, param_grid=grid[key], n_jobs=-1, cv=None)\n",
    "\n",
    "    # Train and score\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    Accuracy = accuracy_score(y_valid, y_pred).round(2)\n",
    "    F1_macro = f1_score(y_valid, y_pred, average = 'macro').round(2)\n",
    "    F1_micro = f1_score(y_valid, y_pred, average = 'micro').round(2)\n",
    "    F1_weighted = f1_score(y_valid, y_pred, average = 'weighted').round(2)\n",
    "    F1_class = f1_score(y_valid, y_pred, average = None).round(2)\n",
    "    Precision = precision_score(y_valid, y_pred, average = None).round(2)\n",
    "    Recall = recall_score(y_valid, y_pred, average = None).round(2)                                         \n",
    "\n",
    "    valid_scores.iloc[i,1]=Accuracy\n",
    "    valid_scores.iloc[i,2]=F1_macro\n",
    "    valid_scores.iloc[i,3]=F1_micro\n",
    "    valid_scores.iloc[i,4]=F1_weighted\n",
    "    valid_scores.iloc[i,5]=F1_class[0]\n",
    "    valid_scores.iloc[i,6]=F1_class[1]\n",
    "    valid_scores.iloc[i,7]=Precision[0]\n",
    "    valid_scores.iloc[i,8]=Precision[1] \n",
    "    valid_scores.iloc[i,9]=Recall[0]\n",
    "    valid_scores.iloc[i,10]=Recall[1]\n",
    "\n",
    "    # Save trained model\n",
    "    clf_best_params[key]=clf.best_params_\n",
    "\n",
    "    # Print iteration and training time\n",
    "    stop = time.time()\n",
    "    valid_scores.iloc[i,11]=np.round((stop - start)/60, 2)\n",
    "\n",
    "\n",
    "    print('Model:', key)\n",
    "    print('Training time (mins):', valid_scores.iloc[i,11])\n",
    "    print('')\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54e8083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifer  Accuracy  F1_macro  F1_micro  F1_weighted  F1_0  F1_1  \\\n",
       "0  LogisticRegression      0.69      0.69      0.69         0.69  0.69  0.69   \n",
       "1                 KNN      0.69      0.68      0.69         0.70  0.74  0.61   \n",
       "2        RandomForest      0.68      0.68      0.68         0.69  0.69  0.67   \n",
       "3             XGBoost      0.69      0.68      0.69         0.70  0.75  0.60   \n",
       "4                LGBM      0.70      0.69      0.70         0.71  0.75  0.63   \n",
       "5          NaiveBayes      0.69      0.69      0.69         0.69  0.69  0.68   \n",
       "\n",
       "   Precision_0  Precision_1  Recall_0  Recall_1  Training time  \n",
       "0         1.00         0.52      0.53      1.00           0.12  \n",
       "1         0.83         0.53      0.68      0.72           0.01  \n",
       "2         0.96         0.52      0.54      0.95           0.28  \n",
       "3         0.81         0.54      0.70      0.69           0.33  \n",
       "4         0.84         0.54      0.67      0.75           0.08  \n",
       "5         1.00         0.52      0.53      1.00           0.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3d7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "best_clf_summary = SelectBestClf(valid_scores, recall_1_threshold, clf_best_params)\n",
    "best_clf = best_clf_summary[2]\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move threshold of classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1c340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.980212, F-Score=0.686\n"
     ]
    }
   ],
   "source": [
    "# Choose the best threshold\n",
    "# recall is above the recall threshold\n",
    "# select the best F1 score \n",
    "\n",
    "# predict probabilities\n",
    "yhat = clf.predict_proba(X_valid)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, probs)\n",
    "# select recall is above the recall threshold                \n",
    "is_good_recall = recall > recall_1_threshold\n",
    "# choose the maximal precision\n",
    "# ix = np.argmax(precision[is_good_recall])\n",
    "\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "\n",
    "\n",
    "# new_y_pred = probs > thresholds[ix]\n",
    "# Accuracy = accuracy_score(y_valid, y_pred).round(2)\n",
    "# F1_micro = f1_score(y_valid, new_y_pred, average = 'micro').round(2)\n",
    "# Precision = precision_score(y_valid, new_y_pred, average = None).round(2)\n",
    "# Recall = recall_score(y_valid, new_y_pred, average = None).round(2)    \n",
    "\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9955178",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "# predict probabilities\n",
    "yhat = clf.predict_proba(X_valid)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, probs)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label=best_clf)\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f73979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([518.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   2., 974.,   0.,   0.,   0.,   0.]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  , 1.02, 1.04, 1.06, 1.08]),\n",
       " <BarContainer object of 54 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probs, bins = np.arange(0, 1.1, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "# define thresholds\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_valid, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = argmax(scores)\n",
    "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, probs)\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "# plot the pr curve for the model\n",
    "no_skill = len(y_valid[y_valid==1]) / len(y_valid)\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label=best_clf)\n",
    "plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc6bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d58a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary = pd.DataFrame()\n",
    "for t,task,task_name in zip(range(len(task_groups)),task_groups, task_group_names):\n",
    "    is_tasks = df_score['task_code'].isin(task).tolist()\n",
    "    df_feature_task = df_feature[is_tasks]\n",
    "    df_score_task = df_score[is_tasks]\n",
    "    df_meta_task = df_meta[is_tasks]\n",
    "    print(task_name)\n",
    "    \n",
    "    # Use only sensor features\n",
    "    df_task = df_feature_task\n",
    "    # Combine sensor features with clinical features\n",
    "#     df_task = pd.concat([df_feature_task, df_meta_task], axis=1)\n",
    "    \n",
    "    # Remove features with nan\n",
    "    df_feature2 = df_task.dropna(axis=1)\n",
    "\n",
    "    # Remove features with zero variance\n",
    "    sel = VarianceThreshold(threshold=0.0001)\n",
    "    df_feature3 = sel.fit_transform(df_feature2)\n",
    "    filter3 = sel.get_support()\n",
    "    feature_names2 = df_feature2.columns\n",
    "    feature_names3 = feature_names2[filter3]\n",
    "    df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "\n",
    "    # Get scores\n",
    "    score = df_score_task['newTremorLabel_GENEActivHand'].values\n",
    "    score = np.array(score, dtype=float)\n",
    "\n",
    "    # Univariate Selection\n",
    "    test = SelectKBest(score_func=f_classif, k=10)\n",
    "    df_feature4 = test.fit_transform(df_feature3, score)\n",
    "    filter4 = test.get_support()\n",
    "    feature_names4 = feature_names3[filter4]\n",
    "    df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "\n",
    "    # PCA\n",
    "    X=df_feature4.values\n",
    "    pca = PCA(n_components=3)\n",
    "    X_new = pca.fit_transform(X)\n",
    "    \n",
    "    # Train/Validation/Test Split\n",
    "    is_train = df_score_task['subject_id'].isin(sb_train).tolist()\n",
    "    is_val = df_score_task['subject_id'].isin(sb_val).tolist()\n",
    "    is_test = df_score_task['subject_id'].isin(sb_test).tolist()\n",
    "    is_train_val = df_score_task['subject_id'].isin(sb_train) | df_score_task['subject_id'].isin(sb_val)\n",
    "    is_train_val = is_train_val.tolist()\n",
    "    \n",
    "    X_train_valid = X_new[is_train_val,:]\n",
    "    y_train_valid = score[is_train_val]\n",
    "    X_train = X_new[is_train,:]\n",
    "    y_train = score[is_train]\n",
    "    X_valid = X_new[is_val,:]\n",
    "    y_valid = score[is_val]\n",
    "    X_test = X_new[is_test,:]\n",
    "    y_test = score[is_test]\n",
    "    \n",
    "    # Classifier evaluation\n",
    "    i=0\n",
    "    clf_best_params=classifiers.copy()\n",
    "    valid_scores=pd.DataFrame({'Classifer':classifiers.keys(),\n",
    "                               'Accuracy': np.zeros(len(classifiers)),\n",
    "                               'F1_macro': np.zeros(len(classifiers)),\n",
    "                               'F1_micro': np.zeros(len(classifiers)),\n",
    "                               'F1_weighted': np.zeros(len(classifiers)),\n",
    "                               'F1_0': np.zeros(len(classifiers)),\n",
    "                               'F1_1': np.zeros(len(classifiers)),                               \n",
    "                               'Precision_0': np.zeros(len(classifiers)),\n",
    "                               'Precision_1': np.zeros(len(classifiers)),\n",
    "                               'Recall_0': np.zeros(len(classifiers)),\n",
    "                               'Recall_1': np.zeros(len(classifiers)),\n",
    "                               'Training time': np.zeros(len(classifiers))})\n",
    "    \n",
    "    for key, classifier in classifiers.items():\n",
    "        start = time.time()\n",
    "        clf = GridSearchCV(estimator=classifier, param_grid=grid[key], n_jobs=-1, cv=None)\n",
    "\n",
    "        # Train and score\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_valid)\n",
    "        Accuracy = accuracy_score(y_valid, y_pred).round(2)\n",
    "        F1_macro = f1_score(y_valid, y_pred, average = 'macro').round(2)\n",
    "        F1_micro = f1_score(y_valid, y_pred, average = 'micro').round(2)\n",
    "        F1_weighted = f1_score(y_valid, y_pred, average = 'weighted').round(2)\n",
    "        F1_class = f1_score(y_valid, y_pred, average = None).round(2)\n",
    "        Precision = precision_score(y_valid, y_pred, average = None).round(2)\n",
    "        Recall = recall_score(y_valid, y_pred, average = None).round(2)                                         \n",
    "        \n",
    "        valid_scores.iloc[i,1]=Accuracy\n",
    "        valid_scores.iloc[i,2]=F1_macro\n",
    "        valid_scores.iloc[i,3]=F1_micro\n",
    "        valid_scores.iloc[i,4]=F1_weighted\n",
    "        valid_scores.iloc[i,5]=F1_class[0]\n",
    "        valid_scores.iloc[i,6]=F1_class[1]\n",
    "        valid_scores.iloc[i,7]=Precision[0]\n",
    "        valid_scores.iloc[i,8]=Precision[1] \n",
    "        valid_scores.iloc[i,9]=Recall[0]\n",
    "        valid_scores.iloc[i,10]=Recall[1]\n",
    "\n",
    "        # Save trained model\n",
    "        clf_best_params[key]=clf.best_params_\n",
    "\n",
    "        # Print iteration and training time\n",
    "        stop = time.time()\n",
    "        valid_scores.iloc[i,11]=np.round((stop - start)/60, 2)\n",
    "        \n",
    "        \n",
    "        print('Model:', key)\n",
    "        print('Training time (mins):', valid_scores.iloc[i,11])\n",
    "        print('')\n",
    "        i+=1\n",
    "    \n",
    "    # Select best classifier based on recall threshold for the positive class and F1 score\n",
    "    is_good_recall_1 = valid_scores['Recall_1'] > recall_1_threshold\n",
    "    if sum(is_good_recall_1) == 0: # recall 1 is below the threshold \n",
    "        best_recall_1 = valid_scores['Recall_1'].max()\n",
    "        is_best = valid_scores['Recall_1'] == best_recall_1\n",
    "        if sum(is_best)>1: # duplicate max recall scores -> compare F1 score\n",
    "            max_index = valid_scores['F1_micro'].loc[is_best].idxmax()\n",
    "        else:\n",
    "            max_index = valid_scores['Recall_1'].idxmax() \n",
    "        best_clf = valid_scores['Classifer'].iloc[max_index]\n",
    "        training_time = valid_scores['Training time'].iloc[max_index]\n",
    "        best_clf_params = clf_best_params[best_clf]\n",
    "        best_F1_micro = valid_scores['F1_micro'].iloc[max_index]\n",
    "\n",
    "    else: # recall 1 is above the threshold -> select the best classifier based on F1 score\n",
    "        best_F1_micro = valid_scores['F1_micro'].loc[is_good_recall_1].max()\n",
    "        is_best = valid_scores['F1_micro'] == best_F1_micro\n",
    "        if sum(is_best)>1: # duplicate max F1 scores -> compare recall score\n",
    "            max_index = valid_scores['Recall_1'].loc[is_best].idxmax()\n",
    "        else:\n",
    "            max_index = valid_scores['F1_micro'].idxmax() \n",
    "        best_clf = valid_scores['Classifer'].iloc[max_index]\n",
    "        training_time = valid_scores['Training time'].iloc[max_index]\n",
    "        best_clf_params = clf_best_params[best_clf] \n",
    "        best_recall_1 = valid_scores['Recall_1'].iloc[max_index]\n",
    "    \n",
    "    clf_summary_round = pd.DataFrame({'title': [title_name],\n",
    "             'task_group': [task_name],\n",
    "             'max_sample_size': [max(counts)],\n",
    "             'upsample_size': [upsample_size],\n",
    "             'best_F1_micro': [best_F1_micro],            \n",
    "             'best_recall_1': [best_recall_1],\n",
    "             'best_clf': [best_clf],\n",
    "             'clf_best_params': [best_clf_params],                         \n",
    "             'valid_scores': [valid_scores]},\n",
    "              index=[t])\n",
    "    clf_summary = pd.concat([clf_summary,clf_summary_round])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8969116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save validation_summary\n",
    "save_file_path = os.path.join(save_path, save_name + '_validation.pkl')\n",
    "# save_file_path = os.path.join(save_path, save_name + '_validation_with_clinical_features.pkl')\n",
    "clf_summary.to_pickle(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary['valid_scores'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c202c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary['valid_scores'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5be4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary['valid_scores'].loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdaa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_summary['valid_scores'].loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb286b83",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation score data\n",
    "questions = ['is_tremor', 'is_sever_tremor']\n",
    "\n",
    "df_valid = pd.DataFrame()\n",
    "for q in questions:\n",
    "    file_path = os.path.join(save_path, q + '_validation.pkl')\n",
    "    df_valid_q = pd.read_pickle(file_path)\n",
    "    df_valid = pd.concat([df_valid,df_valid_q])\n",
    "df_valid = df_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71472fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86943de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['valid_scores'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_summary = df_valid[['title','task_group']].copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0\n",
    "clf_valid_scores = df_valid['valid_scores'].iloc[row]\n",
    "# Select best F1 score\n",
    "best_F1_score = max(clf_valid_scores['F1_weighted'])\n",
    "# Select best classifier based on recall score for positive class\n",
    "best_recall_1 = max(clf_valid_scores['Recall_1'])\n",
    "best_clf = clf_valid_scores['Classifer'].loc[clf_valid_scores['Recall_1']==best_recall_1].values[0]\n",
    "training_time = clf_valid_scores['Training time'].loc[clf_valid_scores['Recall_1']==best_recall_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df94424",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ba389",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a87dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_summary = pd.DataFrame()\n",
    "for row in range(len(df_valid)):\n",
    "    clf_valid_scores = df_valid['valid_scores'].iloc[row]\n",
    "    # Select best classifier based on recall score for positive class\n",
    "    best_recall_1 = max(clf_valid_scores['Recall_1'])\n",
    "    best_clf = clf_valid_scores['Classifer'].loc[clf_valid_scores['Recall_1']==best_recall_1].values[0]\n",
    "    training_time = clf_valid_scores['Training time'].loc[clf_valid_scores['Recall_1']==best_recall_1].values[0]\n",
    "    \n",
    "    df_valid_row = pd.DataFrame({\"title\": df_valid['title'].iloc[row],\n",
    "                                \"task_group\": df_valid['task_group'].iloc[row],\n",
    "                                 \"best_F1_score\": max(clf_valid_scores['F1_weighted']),\n",
    "                                 \"best_recall_1\": best_recall_1,\n",
    "                                 \"best_clf\": best_clf,\n",
    "                                 \"training_time\": training_time},\n",
    "                               index = [row])\n",
    "    df_valid_summary = pd.concat([df_valid_summary,df_valid_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2084f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_summary.drop([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503cc800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ad11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15ef61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15b8f259",
   "metadata": {},
   "source": [
    "# For feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split\n",
    "is_train = df_score['subject_id'].isin(sb_train).tolist()\n",
    "is_val = df_score['subject_id'].isin(sb_val).tolist()\n",
    "is_test = df_score['subject_id'].isin(sb_test).tolist()\n",
    "is_train_val = df_score['subject_id'].isin(sb_train) | df_score['subject_id'].isin(sb_val)\n",
    "is_train_val = is_train_val.tolist()\n",
    "\n",
    "# df_feature_train = df_feature[is_train]\n",
    "# df_score_train = df_score[is_train]\n",
    "# df_feature_val = df_feature[is_val]\n",
    "# df_score_val = df_score[is_val]\n",
    "# df_feature_test = df_feature[is_test]\n",
    "# df_score_test = df_score[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with nan\n",
    "df_feature2 = df_feature.dropna(axis=1)\n",
    "\n",
    "# Remove features with zero variance\n",
    "sel = VarianceThreshold(threshold=0.0001)\n",
    "df_feature3 = sel.fit_transform(df_feature2)\n",
    "filter3 = sel.get_support()\n",
    "feature_names2 = df_feature2.columns\n",
    "feature_names3 = feature_names2[filter3]\n",
    "df_feature3 = pd.DataFrame(df_feature3, columns=feature_names3)\n",
    "\n",
    "# Get scores\n",
    "score = df_score['newTremorLabel_GENEActivHand'].values\n",
    "# score = df_score['tremor_GENEActivHand'].values\n",
    "# score = df_score['tremor_PebbleHand'].values\n",
    "score = np.array(score, dtype=float)\n",
    "\n",
    "# Univariate Selection\n",
    "test = SelectKBest(score_func=f_classif, k=10)\n",
    "df_feature4 = test.fit_transform(df_feature3, score)\n",
    "filter4 = test.get_support()\n",
    "feature_names4 = feature_names3[filter4]\n",
    "df_feature4 = pd.DataFrame(df_feature4, columns=feature_names4)\n",
    "\n",
    "# PCA\n",
    "X=df_feature4.values\n",
    "pca = PCA(n_components=3)\n",
    "X_new = pca.fit_transform(X)\n",
    "\n",
    "# train/validation/test split\n",
    "X_train_valid = X_new[is_train_val,:]\n",
    "y_train_valid = score[is_train_val]\n",
    "X_train = X_new[is_train,:]\n",
    "y_train = score[is_train]\n",
    "X_valid = X_new[is_val,:]\n",
    "y_valid = score[is_val]\n",
    "X_test = X_new[is_test,:]\n",
    "y_test = score[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = pca.fit(X)\n",
    "np.cumsum(fit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2de447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac425ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe39e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabdcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a20e0718",
   "metadata": {},
   "source": [
    "# For test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best classifiers\n",
    "NB_best = GaussianNB(**clf_best_params[\"NaiveBayes\"])\n",
    "NB_best.fit(X_train_valid, y_train_valid)\n",
    "y_pred = NB_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68884e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best classifiers\n",
    "LR_best = LogisticRegression(**clf_best_params[\"LogisticRegression\"], verbose=False, random_state=0, solver = 'liblinear')\n",
    "LR_best.fit(X_train_valid, y_train_valid)\n",
    "y_pred = LR_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5888bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best classifiers\n",
    "RF_best = RandomForestClassifier(**clf_best_params[\"RandomForest\"], verbose=False, random_state=0)\n",
    "RF_best.fit(X_train_valid, y_train_valid)\n",
    "y_pred = RF_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0101d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae930bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = accuracy_score(y_test, y_pred)\n",
    "Precision = precision_score(y_test, y_pred, average = None)\n",
    "Recall = recall_score(y_test, y_pred, average = None)\n",
    "F1 = f1_score(y_test, y_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_weighted = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d343134",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491238fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f214fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
