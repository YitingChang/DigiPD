{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a879e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor data\n",
    "# Identify intervals with missing data in the raw signals\n",
    "# Resmaple the time series with a smapling rate of 50 Hz\n",
    "# Temoprally align the signals collected using different devices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0671a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"E:\\\\WS4PD_data\"\n",
    "os.chdir(direc)\n",
    "# load data\n",
    "demogra_data = pd.read_csv(\"Demographics_data.csv\")\n",
    "task_score = pd.read_csv(\"Task_scores_part_I.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b876b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify intervals with missing data in the raw signals\n",
    "# Check data type\n",
    "# GENEActiv\n",
    "# device = 'GENEActiv'\n",
    "# visit = 1\n",
    "# day = 1\n",
    "# sample_rate = 50\n",
    "# subject_ids = task_score.subject_id.unique()\n",
    "# summary = pd.DataFrame()\n",
    "\n",
    "# for sb in subject_ids:\n",
    "#     sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "#     sensor_data = pd.read_table(sensor_path)\n",
    "#     is_float = sensor_data.dtypes == 'float'\n",
    "#     interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "#     is_dt = interval == (1/sample_rate)\n",
    "#     missing_ts = [i for i, val in enumerate(~is_dt) if val]  \n",
    "        \n",
    "#     summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'GENEActiv_X': is_float[1],\n",
    "#             'GENEActiv_Y': is_float[2], 'GENEActiv_Z': is_float[3],\n",
    "#              'GENEActiv_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "    \n",
    "#     summary = pd.concat([summary,summary_sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify intervals with missing data in the raw signals\n",
    "# Check data type\n",
    "# Pebble\n",
    "device = 'Pebble'\n",
    "visit = 1\n",
    "day = 1\n",
    "sample_rate = 50\n",
    "subject_ids = task_score.subject_id.unique()\n",
    "summary = pd.DataFrame()\n",
    "# 4_BOS didn't have Pebble data\n",
    "subject_ids = np.delete(subject_ids, np.where(subject_ids == '4_BOS'))\n",
    "for sb in subject_ids:\n",
    "    sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "#     sensor_data = pd.read_table(sensor_path)\n",
    "    sensor_data = pd.read_pickle(sensor_path)\n",
    "    is_float = sensor_data.dtypes == 'float'\n",
    "    interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "    is_dt = interval == (1/sample_rate)\n",
    "    missing_ts = [i for i, val in enumerate(~is_dt) if val]  \n",
    "    summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "        'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "         'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "    summary = pd.concat([summary,summary_sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e3985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'Pebble'\n",
    "visit = 2\n",
    "day = 4\n",
    "sample_rate = 50\n",
    "subject_ids = task_score.subject_id.unique()\n",
    "summary = pd.DataFrame()\n",
    "# 4_BOS didn't have Pebble data\n",
    "subject_ids = np.delete(subject_ids, np.where(subject_ids == '4_BOS'))\n",
    "sb = subject_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170d4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_pickle(sensor_path)\n",
    "is_nan = [np.isnan(x) for x in sensor_data['Pebble_X']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8ae6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179648"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(is_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd65710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yiting\\Anaconda3\\envs\\ws4pd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (1,2,3,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Pebble_X</th>\n",
       "      <th>Pebble_Y</th>\n",
       "      <th>Pebble_Z</th>\n",
       "      <th>Pebble_Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.427414e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.427414e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.427414e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.427414e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.427414e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899639</th>\n",
       "      <td>1.427472e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899640</th>\n",
       "      <td>1.427472e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899641</th>\n",
       "      <td>1.427472e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899642</th>\n",
       "      <td>1.427472e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899643</th>\n",
       "      <td>1.427472e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2899644 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    Pebble_X    Pebble_Y    Pebble_Z Pebble_Magnitude\n",
       "0        1.427414e+09         NaN         NaN         NaN              NaN\n",
       "1        1.427414e+09         NaN         NaN         NaN              NaN\n",
       "2        1.427414e+09         NaN         NaN         NaN              NaN\n",
       "3        1.427414e+09         NaN         NaN         NaN              NaN\n",
       "4        1.427414e+09         NaN         NaN         NaN              NaN\n",
       "...               ...         ...         ...         ...              ...\n",
       "2899639  1.427472e+09         NaN         NaN         NaN              NaN\n",
       "2899640  1.427472e+09         NaN         NaN         NaN              NaN\n",
       "2899641  1.427472e+09         NaN         NaN         NaN              NaN\n",
       "2899642  1.427472e+09         NaN         NaN         NaN              NaN\n",
       "2899643  1.427472e+09         NaN         NaN         NaN              NaN\n",
       "\n",
       "[2899644 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sensor_path = os.path.join(direc, 'Pebble_rawdata', sb, 'rawdata_day'+str(day)+'.txt')\n",
    "raw_sensor_data = pd.read_table(raw_sensor_path)\n",
    "raw_sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e1d8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6_BOS'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c663c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_nan = [np.isnan(x) for x in sensor_data['Pebble_X']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8757ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1665c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pebble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca55d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit = 2 (day 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2 = pd.DataFrame()\n",
    "for sb in subject_ids:\n",
    "    sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "    sensor_data = pd.read_table(sensor_path)\n",
    "    is_str = [isinstance(xxi, str) for xxi in sensor_data['Pebble_X']]\n",
    "    # remove whitespaces of string variables\n",
    "    sensor_data['Pebble_X'][is_str] = sensor_data['Pebble_X'][is_str].str.strip()\n",
    "    sensor_data['Pebble_Y'][is_str] = sensor_data['Pebble_Y'][is_str].str.strip()\n",
    "    sensor_data['Pebble_Z'][is_str] = sensor_data['Pebble_Z'][is_str].str.strip()\n",
    "    sensor_data['Pebble_Magnitude'][is_str] = sensor_data['Pebble_Magnitude'][is_str].str.strip()\n",
    "\n",
    "    # remove timestamps having NaN\n",
    "    is_nan = sensor_data['Pebble_X'].str.contains('NaN') | sensor_data['Pebble_X'].str.contains('nan')\n",
    "    sensor_data2 = sensor_data.drop(labels = sensor_data[is_nan].index, axis=0)\n",
    "    # converting data type to float\n",
    "    sensor_data3 = sensor_data2.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                        \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "    # fill nan with the average value\n",
    "    sensor_data.Pebble_X[is_nan] = sensor_data3.mean().Pebble_X\n",
    "    sensor_data.Pebble_Y[is_nan] = sensor_data3.mean().Pebble_Y\n",
    "    sensor_data.Pebble_Z[is_nan] = sensor_data3.mean().Pebble_Z\n",
    "    sensor_data.Pebble_Magnitude[is_nan] = sensor_data3.mean().Pebble_Magnitude\n",
    "    # converting data type to float\n",
    "    sensor_data = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                        \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "    # save corrected data\n",
    "    sensor_data.to_pickle(sensor_path)\n",
    "    \n",
    "    # Check data type\n",
    "    is_float = sensor_data.dtypes == 'float'\n",
    "    # Identify intervals with missing data in the raw signals\n",
    "    interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "    is_dt = interval == (1/sample_rate)\n",
    "    missing_ts = [i for i, val in enumerate(~is_dt) if val]  \n",
    "    summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "        'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "         'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "    \n",
    "    summary2 = pd.concat([summary2,summary_sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d974a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab018fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4_NYC\n",
    "sb = '4_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_pickle(sensor_path)\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "# remove interval ~= 0.02\n",
    "sensor_data = sensor_data.drop(labels=missing_ts, axis=0)\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "# Check data type\n",
    "is_float = sensor_data3.dtypes == 'float'\n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data2.to_pickle(save_path)\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_NYC\n",
    "# 3 intervals are 0.01\n",
    "# remove one of the timestamps but still 0.01 interval left\n",
    "sb = '10_NYC'\n",
    "sensor_path = os.path.join(direc, 'Pebble_rawdata', sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_str = [isinstance(xxi, str) for xxi in sensor_data['Pebble_X']]\n",
    "# remove whitespaces of string variables\n",
    "sensor_data['Pebble_X'][is_str] = sensor_data['Pebble_X'][is_str].str.strip()\n",
    "sensor_data['Pebble_Y'][is_str] = sensor_data['Pebble_Y'][is_str].str.strip()\n",
    "sensor_data['Pebble_Z'][is_str] = sensor_data['Pebble_Z'][is_str].str.strip()\n",
    "sensor_data['Pebble_Magnitude'][is_str] = sensor_data['Pebble_Magnitude'][is_str].str.strip()\n",
    "# remove timestamps having NaN\n",
    "is_nan = sensor_data['Pebble_X'].str.contains('NaN') | sensor_data['Pebble_X'].str.contains('nan')\n",
    "sensor_data2 = sensor_data.drop(labels = sensor_data[is_nan].index, axis=0)\n",
    "# converting data type to float\n",
    "sensor_data3 = sensor_data2.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "# fill nan with the average value\n",
    "sensor_data.Pebble_X[is_nan] = sensor_data3.mean().Pebble_X\n",
    "sensor_data.Pebble_Y[is_nan] = sensor_data3.mean().Pebble_Y\n",
    "sensor_data.Pebble_Z[is_nan] = sensor_data3.mean().Pebble_Z\n",
    "sensor_data.Pebble_Magnitude[is_nan] = sensor_data3.mean().Pebble_Magnitude\n",
    "# converting data type to float\n",
    "sensor_data = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "# Removing interval ~=0.02\n",
    "sensor_data2 = sensor_data.drop(labels= [1561400], axis=0)\n",
    "# Check data type\n",
    "is_float = sensor_data2.dtypes == 'float'\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data2.to_pickle(save_path)\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12_NYC\n",
    "# 3 intervals are 0.01\n",
    "# remove one of the timestamps but still 0.01 interval left\n",
    "sb = '12_NYC'\n",
    "sensor_path = os.path.join(direc, 'Pebble_rawdata', sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_str = [isinstance(xxi, str) for xxi in sensor_data['Pebble_X']]\n",
    "# remove whitespaces of string variables\n",
    "sensor_data['Pebble_X'][is_str] = sensor_data['Pebble_X'][is_str].str.strip()\n",
    "sensor_data['Pebble_Y'][is_str] = sensor_data['Pebble_Y'][is_str].str.strip()\n",
    "sensor_data['Pebble_Z'][is_str] = sensor_data['Pebble_Z'][is_str].str.strip()\n",
    "sensor_data['Pebble_Magnitude'][is_str] = sensor_data['Pebble_Magnitude'][is_str].str.strip()\n",
    "# remove timestamps having NaN\n",
    "is_nan = sensor_data['Pebble_X'].str.contains('NaN') | sensor_data['Pebble_X'].str.contains('nan')\n",
    "sensor_data2 = sensor_data.drop(labels = sensor_data[is_nan].index, axis=0)\n",
    "# converting data type to float\n",
    "sensor_data3 = sensor_data2.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "# fill nan with the average value\n",
    "sensor_data.Pebble_X[is_nan] = sensor_data3.mean().Pebble_X\n",
    "sensor_data.Pebble_Y[is_nan] = sensor_data3.mean().Pebble_Y\n",
    "sensor_data.Pebble_Z[is_nan] = sensor_data3.mean().Pebble_Z\n",
    "sensor_data.Pebble_Magnitude[is_nan] = sensor_data3.mean().Pebble_Magnitude\n",
    "# converting data type to float\n",
    "sensor_data = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "# Removing interval ~=0.02\n",
    "sensor_data2 = sensor_data.drop(labels= [2521526], axis=0)\n",
    "# Check data type\n",
    "is_float = sensor_data2.dtypes == 'float'\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data2.to_pickle(save_path)\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df293a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit = 1 (day 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of Pebble data is string not float\n",
    "summary2 = pd.DataFrame()\n",
    "for sb in subject_ids:\n",
    "    sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "    sensor_data = pd.read_table(sensor_path)\n",
    "    # remove whitespaces\n",
    "    sensor_data['Pebble_X'] = sensor_data['Pebble_X'].str.strip()\n",
    "    sensor_data['Pebble_Y'] = sensor_data['Pebble_Y'].str.strip()\n",
    "    sensor_data['Pebble_Z'] = sensor_data['Pebble_Z'].str.strip()\n",
    "    sensor_data['Pebble_Magnitude'] = sensor_data['Pebble_Magnitude'].str.strip()\n",
    "    \n",
    "    # remove timestamps having NaN\n",
    "    is_nan = sensor_data['Pebble_X'].str.contains('NaN') | sensor_data['Pebble_X'].str.contains('nan')\n",
    "    sensor_data2 = sensor_data.drop(labels = sensor_data[is_nan].index, axis=0)\n",
    "    # converting data type to float\n",
    "    sensor_data3 = sensor_data2.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                        \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "    # fill nan with the average value\n",
    "    sensor_data.Pebble_X[is_nan] = sensor_data3.mean().Pebble_X\n",
    "    sensor_data.Pebble_Y[is_nan] = sensor_data3.mean().Pebble_Y\n",
    "    sensor_data.Pebble_Z[is_nan] = sensor_data3.mean().Pebble_Z\n",
    "    sensor_data.Pebble_Magnitude[is_nan] = sensor_data3.mean().Pebble_Magnitude\n",
    "    # converting data type to float\n",
    "    sensor_data = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                        \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "    # save corrected data\n",
    "    sensor_data.to_pickle(sensor_path)\n",
    "    \n",
    "    # Check data type\n",
    "    is_float = sensor_data.dtypes == 'float'\n",
    "    # Identify intervals with missing data in the raw signals\n",
    "    interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "    is_dt = interval == (1/sample_rate)\n",
    "    missing_ts = [i for i, val in enumerate(~is_dt) if val]  \n",
    "    summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "        'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "         'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "    \n",
    "    summary2 = pd.concat([summary2,summary_sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5_NYC\n",
    "# data is float not string \n",
    "sb = '5_NYC'\n",
    "sensor_path = os.path.join(direc, 'Pebble_rawdata', sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "# Check data type\n",
    "is_float = sensor_data2.dtypes == 'float'\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]  \n",
    "\n",
    "# removing missing data\n",
    "sensor_data3 = sensor_data2.drop(labels=missing_ts, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data3.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data3.to_pickle(save_path)\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d24958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6_NYC\n",
    "# One part of data is float and the other part of data is string \n",
    "sb = '6_NYC'\n",
    "sensor_path = os.path.join(direc, 'Pebble_rawdata', sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_str = [isinstance(xxi, str) for xxi in sensor_data['Pebble_X']]\n",
    "# remove whitespaces of string variables\n",
    "sensor_data['Pebble_X'][is_str] = sensor_data['Pebble_X'][is_str].str.strip()\n",
    "sensor_data['Pebble_Y'][is_str] = sensor_data['Pebble_Y'][is_str].str.strip()\n",
    "sensor_data['Pebble_Z'][is_str] = sensor_data['Pebble_Z'][is_str].str.strip()\n",
    "sensor_data['Pebble_Magnitude'][is_str] = sensor_data['Pebble_Magnitude'][is_str].str.strip()\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data.astype({\"Pebble_X\": float, \"Pebble_Y\": float, \"Pebble_Z\": float,\n",
    "                                    \"Pebble_Magnitude\": float,}, errors='raise')\n",
    "# Identify intervals with missing data in the raw signals\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "# removing missing data\n",
    "sensor_data3 = sensor_data2.drop(labels=missing_ts, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data3.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# Check data type\n",
    "is_float = sensor_data3.dtypes == 'float'\n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data3.to_pickle(save_path)\n",
    "\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11_NYC\n",
    "# Remove repeated timestamp\n",
    "sb = '11_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_pickle(sensor_path)\n",
    "sensor_data2 = sensor_data.drop(labels = [0,1,2], axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val] \n",
    "# Check data type\n",
    "is_float = sensor_data2.dtypes == 'float'\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data2.to_pickle(save_path)\n",
    "\n",
    "summary_sb = pd.DataFrame(data= {'subject_id': sb, 'timestamp': is_float[0], 'Pebble_X': is_float[1],\n",
    "    'Pebble_Y': is_float[2], 'Pebble_Z': is_float[3],\n",
    "     'Pebble_Magnitude': is_float[4], 'missing_timestamp':[[missing_ts]]})\n",
    "summary_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dac383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENEActiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ad0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit = 2 (day 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4_NYC\n",
    "# missing timestamp problem\n",
    "sb = '4_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "missing_ts2 = [2442339, 2442340]\n",
    "missing_ts3 = missing_ts + missing_ts2\n",
    "# removing missing data\n",
    "sensor_data2 = sensor_data.drop(labels=missing_ts3, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6722609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_NYC\n",
    "# missing timestamp problem\n",
    "# NaN: range(0, 1561402)\n",
    "# Only 4 hour recording \n",
    "sb = '10_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# removing missing data\n",
    "missing_ts2 = range(missing_ts[-1]+1)\n",
    "sensor_data2 = sensor_data.drop(labels=missing_ts2, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d17c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12_NYC\n",
    "# missing timestamp problem\n",
    "sb = '12_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "missing_ts2 = [2521528]\n",
    "missing_ts3 = missing_ts + missing_ts2\n",
    "# removing missing data\n",
    "sensor_data2 = sensor_data.drop(labels=missing_ts3, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(day)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4744275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c4425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96093924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit = 1 (day 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6_BOS\n",
    "# missing timestamp problem\n",
    "sb = '6_BOS'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# removing overlappping timestamps\n",
    "overlap_ts = sensor_data.timestamp.loc[2668989:] < sensor_data.timestamp.loc[2668988]\n",
    "overlap_index = overlap_ts.index\n",
    "sensor_data2 = sensor_data.drop(labels=overlap_index, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "is_float = sensor_data2.dtypes\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df57445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5_NYC\n",
    "sb = '5_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# removing missing data\n",
    "sensor_data2 = sensor_data.drop(labels=missing_ts, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11501be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6_NYC\n",
    "sb = '6_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# removing missing data\n",
    "sensor_data2 = sensor_data.drop(labels=missing_ts, axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976958a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60078f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db239c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11_NYC\n",
    "sb = '11_NYC'\n",
    "sensor_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'.txt')\n",
    "sensor_data = pd.read_table(sensor_path)\n",
    "is_float = sensor_data.dtypes == 'float'\n",
    "interval = np.round_(np.diff(sensor_data.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# removing missing data\n",
    "sensor_data2 = sensor_data.drop(labels=[0,1,2], axis=0)\n",
    "interval = np.round_(np.diff(sensor_data2.timestamp),2)\n",
    "is_dt = interval == (1/sample_rate)\n",
    "missing_ts = [i for i, val in enumerate(~is_dt) if val]\n",
    "# converting data type to float\n",
    "sensor_data2 = sensor_data2.astype({\"GENEActiv_X\": float, \"GENEActiv_Y\": float, \"GENEActiv_Z\": float,\n",
    "                                    \"GENEActiv_Magnitude\": float,}, errors='raise')\n",
    "is_float = sensor_data2.dtypes\n",
    "# save corrected data\n",
    "save_path = os.path.join(direc, device, sb, 'rawdata_day'+str(visit)+'_corrected.txt')\n",
    "sensor_data2.to_csv(save_path, index = None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf47501",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf41f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_float"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
